# 이미지 딥러닝 응용 개요

- **주요 내용**: CNN 리뷰, Transfer Learning 개념, Style Transfer 원리
- **실습 여부**: X (이론 중심)
- **목표**: 이미지 딥러닝의 핵심 개념을 복습하고, Neural Style Transfer의 원리를 이해합니다.

## 이론

### 1. CNN (Convolutional Neural Networks) 리뷰
CNN은 이미지 처리에 특화된 딥러닝 모델로, 이미지의 지역적 특징(에지, 텍스처 등)을 효과적으로 추출합니다. 주요 구성 요소는 다음과 같습니다:
- **Convolution Layer (합성곱 층)**: 필터(커널)를 사용하여 이미지에서 특징을 추출합니다. 필터는 학습 가능한 파라미터로, 이미지의 특정 패턴(예: 수직선, 대각선)을 감지합니다.
- **Pooling Layer (풀링 층)**: 공간적 크기를 줄여 계산량을 감소시키고 과적합을 방지합니다. Max Pooling은 가장 큰 값을 선택해 특징을 압축합니다.
- **Fully Connected Layer (완전 연결 층)**: 추출된 특징을 기반으로 분류나 회귀 작업을 수행합니다.
- **활성화 함수**: ReLU(Rectified Linear Unit, $f(x) = \max(0, x)$)는 비선형성을 추가해 복잡한 패턴 학습을 가능하게 합니다.

**활용 사례**: VGG, ResNet, Inception 등의 CNN 아키텍처는 이미지 분류, 객체 탐지, 얼굴 인식 등에 사용됩니다.

### 2. Transfer Learning 개념
Transfer Learning은 사전 학습된(pre-trained) 모델의 가중치를 새로운 작업에 재사용하는 기법입니다. 특히 데이터가 부족하거나 학습 자원이 제한적일 때 효과적입니다.
- **원리**: 대규모 데이터셋(ImageNet 등)으로 학습된 모델(VGG, ResNet 등)의 가중치를 가져와 새로운 작업에 맞게 미세 조정(fine-tuning)합니다.
- **장점**:
  - 학습 시간 단축
  - 소량 데이터로도 높은 성능
  - 사전 학습된 모델은 일반적인 이미지 특징(에지, 텍스처 등)을 이미 학습한 상태
- **절차**:
  1. 사전 학습된 모델을 로드합니다.
  2. 새로운 데이터에 맞게 마지막 층(fully connected layer)을 교체하거나, 일부 층을 재학습합니다.
- **활용 사례**: 이미지 분류, 객체 탐지, 스타일 전이, 의료 영상 분석 등.

### 3. Style Transfer 원리
Neural Style Transfer(NST)는 한 이미지의 콘텐츠(구조)와 다른 이미지의 스타일(텍스처, 색상)을 결합하여 새로운 이미지를 생성하는 기술입니다.
- **핵심 아이디어**:
  - **콘텐츠 손실(Content Loss)**: 생성 이미지와 콘텐츠 이미지가 구조적으로 유사해야 합니다. CNN의 깊은 층에서 추출된 특징 맵을 비교합니다.
  - **스타일 손실(Style Loss)**: 생성 이미지와 스타일 이미지가 텍스처, 색상 패턴 등에서 유사해야 합니다. Gram Matrix를 사용해 특징 간 상관관계를 계산합니다.
  - **최적화**: 콘텐츠 손실과 스타일 손실의 가중 합을 최소화하도록 생성 이미지를 업데이트합니다(Gradient Descent).
- **사용 모델**: VGG19와 같은 사전 학습된 CNN을 주로 사용. VGG19는 계층적 특징(저수준: 에지, 고수준: 객체 구조)을 효과적으로 추출합니다.
- **과정**:
  1. 콘텐츠 이미지와 스타일 이미지를 입력.
  2. VGG19를 통해 각 이미지의 특징을 추출.
  3. 초기 생성 이미지(랜덤 노이즈 또는 콘텐츠 이미지)를 설정.
  4. 손실 함수를 최소화하도록 반복적으로 최적화.

## 수식

### 콘텐츠 손실 (Content Loss)
$$
L_{\text{content}} = \frac{1}{2} \sum (F^l - P^l)^2
$$

### 스타일 손실 (Style Loss)
$$
L_{\text{style}} = \sum_l w_l \frac{1}{4 N_l^2 M_l^2} \sum (G^l - A^l)^2
$$

### 총 손실 (Total Loss)
$$
L_{\text{total}} = \alpha L_{\text{content}} + \beta L_{\text{style}}
$$

## 수식 변수 설명
- **콘텐츠 손실 변수**:
  - $F^l$: 생성 이미지의 $l$번째 층 특징 맵 (Feature map of the generated image at layer $l$)
  - $P^l$: 콘텐츠 이미지의 $l$번째 층 특징 맵 (Feature map of the content image at layer $l$)

- **스타일 손실 변수**:
  - $G^l$: 생성 이미지의 Gram Matrix (Gram matrix of the generated image)
  - $A^l$: 스타일 이미지의 Gram Matrix (Gram matrix of the style image)
  - $w_l$: 각 층의 가중치 (Weight for layer $l$)
  - $N_l$: $l$번째 층의 채널 수 (Number of channels in layer $l$)
  - $M_l$: $l$번째 층의 특징 맵 크기 (높이 × 너비, Size of the feature map in layer $l$)

- **총 손실 변수**:
  - $\alpha$: 콘텐츠 손실 가중치 (Weight for content loss)
  - $\beta$: 스타일 손실 가중치 (Weight for style loss)

## 수식 설명
### 1. 콘텐츠 손실 (Content Loss)
- **의미**: 생성 이미지가 원래 콘텐츠 이미지(예: 고양이 사진)의 모양을 얼마나 잘 유지하는지 확인합니다.
- **계산 방법**:
  - CNN(VGG19 같은 모델)을 사용해 이미지의 구조(윤곽, 형태)를 추출합니다.
  - 생성 이미지($F^l$)와 콘텐츠 이미지($P^l$)의 구조 차이를 제곱($(F^l - P^l)^2$)해서 계산합니다.
  - 제곱한 차이를 모두 합($\sum$)하고, 숫자를 작게 만들기 위해 1/2를 곱합니다.
- **예시**: 고양이 사진을 그리면서 원본 사진의 고양이 모양과 얼마나 비슷한지 확인하는 점수입니다.

### 2. 스타일 손실 (Style Loss)
- **의미**: 생성 이미지가 스타일 이미지(예: 반 고흐의 "별이 빛나는 밤")의 색감, 텍스처를 얼마나 잘 따라하는지 확인합니다.
- **계산 방법**:
  - Gram Matrix($G^l$, $A^l$)는 이미지의 스타일(색상 패턴, 텍스처)을 나타냅니다.
  - 생성 이미지와 스타일 이미지의 Gram Matrix 차이를 제곱($(G^l - A^l)^2$)해서 계산합니다.
  - $\frac{1}{4 N_l^2 M_l^2}$: 숫자를 공정하게 비교하기 위해 크기를 조정합니다.
  - $w_l$: CNN의 각 층(에지, 색상, 복잡한 패턴 등)의 중요도를 조절합니다.
  - 여러 층의 스타일 차이를 합($\sum_l$)합니다.
- **예시**: 그림에 반 고흐 특유의 소용돌이 무늬와 색감을 얼마나 잘 넣었는지 확인하는 점수입니다.

### 3. 총 손실 (Total Loss)
- **의미**: 콘텐츠 손실과 스타일 손실을 합쳐, 생성 이미지가 콘텐츠와 스타일을 모두 잘 반영하도록 만듭니다.
- **계산 방법**:
  - 콘텐츠 손실($L_{\text{content}}$)과 스타일 손실($L_{\text{style}}$)을 각각 가중치($\alpha$, $\beta$)로 곱해 합칩니다.
  - $\alpha$: 콘텐츠(고양이 모양)의 중요도를 조절.
  - $\beta$: 스타일(반 고흐 느낌)의 중요도를 조절.
- **예시**: 고양이 모양과 반 고흐 스타일을 적절히 섞은 그림을 만들기 위해 두 점수를 조화롭게 맞추는 과정입니다.